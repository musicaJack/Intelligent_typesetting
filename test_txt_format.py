#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•TXTæ ¼å¼çš„ç»“æ„åŒ–æ ‡ç­¾ç”Ÿæˆ
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.models.ckip_processor import CkipProcessor, TokenInfo, EntityInfo

def test_txt_format():
    """æµ‹è¯•TXTæ ¼å¼çš„ç»“æ„åŒ–æ ‡ç­¾"""
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = CkipProcessor(model_name="bert-base")
    processor.chars_per_line = 16
    processor.lines_per_page = 12
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """å“ˆåˆ©Â·æ³¢ç‰¹ä¸é­”æ³•çŸ³

ä¸»è¦äººç‰©è¡¨

å“ˆåˆ©Â·æ³¢ç‰¹ï¼šæœ¬ä¹¦ä¸»äººå…¬ï¼Œéœæ ¼æ²ƒèŒ¨é­”æ³•å­¦æ ¡ä¸€å¹´çº§å­¦ç”Ÿ
ä½©å¦®ï¼šå“ˆåˆ©çš„å§¨å¦ˆ
å¼—å†œÂ·å¾·æ€ç¤¼ï¼šå“ˆåˆ©çš„å§¨çˆ¶
è¾¾åŠ›ï¼šå“ˆåˆ©çš„è¡¨å“¥ï¼Œå¾·æ€ç¤¼å¤«å¦‡çš„å„¿å­
é˜¿ä¸æ€Â·é‚“å¸ƒåˆ©å¤šï¼šéœæ ¼æ²ƒèŒ¨é­”æ³•å­¦æ ¡æ ¡é•¿
éº¦æ ¼æ•™æˆï¼šéœæ ¼æ²ƒèŒ¨é­”æ³•å­¦æ ¡å‰¯æ ¡é•¿
æ–¯å†…æ™®æ•™æˆï¼šéœæ ¼æ²ƒèŒ¨é­”æ³•å­¦æ ¡é­”è¯è¯¾æ•™å¸ˆ

ç¬¬1ç«  å¤§éš¾ä¸æ­»çš„ç”·å­©

å®¶ä½å¥³è´è·¯4å·çš„å¾·æ€ç¤¼å¤«å¦‡æ€»æ˜¯å¾—æ„åœ°è¯´ä»–ä»¬æ˜¯éå¸¸è§„çŸ©çš„äººå®¶ã€‚æ‹œæ‰˜ï¼Œæ‹œæ‰˜äº†ã€‚ä»–ä»¬ä»æ¥è·Ÿç¥ç§˜å¤æ€ªçš„äº‹ä¸æ²¾è¾¹ï¼Œå› ä¸ºä»–ä»¬æ ¹æœ¬ä¸ç›¸ä¿¡é‚£äº›é‚ªé—¨æ­ªé“ã€‚å¼—å†œÂ·å¾·æ€æœ­å…ˆç”Ÿåœ¨ä¸€å®¶åå«æ ¼æœ—å®çš„å…¬å¸åšä¸»ç®¡ï¼Œå…¬å¸ç”Ÿäº§é’»æœºã€‚"""
    
    # å¤„ç†æ–‡æœ¬
    result = processor.process_text(test_text)
    tokens = [TokenInfo(**token_dict) for token_dict in result["tokens"]]
    entities = [EntityInfo(**entity_dict) for entity_dict in result["entities"]]
    
    # ç”Ÿæˆé¡µé¢å¸ƒå±€
    pages = processor._generate_pages(tokens, entities)
    
    # ç”ŸæˆTXTå†…å®¹
    txt_content = processor._generate_txt_content(pages)
    
    # ä¿å­˜æµ‹è¯•æ–‡ä»¶
    with open("test_structured.txt", "w", encoding="utf-8") as f:
        f.write(txt_content)
    
    print("âœ… æµ‹è¯•æ–‡ä»¶å·²ç”Ÿæˆ: test_structured.txt")
    print(f"ğŸ“„ æ€»é¡µæ•°: {len(pages)}")
    print(f"ğŸ“ æ€»è¡Œæ•°: {sum(len(page.lines) for page in pages)}")
    
    # éªŒè¯æ ‡ç­¾æ ¼å¼
    lines = txt_content.split('\n')
    page_starts = [line for line in lines if line.startswith('<PAGE_') and line.endswith('_START>')]
    page_ends = [line for line in lines if line.startswith('<PAGE_') and line.endswith('_END>')]
    line_tags = [line for line in lines if line.startswith('<LINE_')]
    
    print(f"ğŸ·ï¸ é¡µé¢å¼€å§‹æ ‡ç­¾: {len(page_starts)}")
    print(f"ğŸ·ï¸ é¡µé¢ç»“æŸæ ‡ç­¾: {len(page_ends)}")
    print(f"ğŸ·ï¸ è¡Œæ ‡ç­¾: {len(line_tags)}")
    
    # æ£€æŸ¥ç¬¬ä¸€é¡µæ˜¯å¦æœ‰STARTæ ‡ç­¾
    if any('PAGE_001_START' in line for line in lines):
        print("âœ… ç¬¬ä¸€é¡µåŒ…å«PAGE_001_STARTæ ‡ç­¾")
    else:
        print("âŒ ç¬¬ä¸€é¡µç¼ºå°‘PAGE_001_STARTæ ‡ç­¾")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œå†…å®¹
    print("\nğŸ“– æ–‡ä»¶å‰20è¡Œå†…å®¹:")
    for i, line in enumerate(lines[:20]):
        print(f"{i+1:2d}: {line}")
    
    return txt_content

if __name__ == "__main__":
    test_txt_format() 