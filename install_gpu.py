#!/usr/bin/env python3
"""
GPUç‰ˆæœ¬å®‰è£…è„šæœ¬

ä¸“é—¨ä¸º4090Dæ˜¾å¡å®‰è£…GPUç‰ˆæœ¬çš„PyTorchå’Œç›¸å…³ä¾èµ–ã€‚
"""

import subprocess
import sys
import platform
import os

def check_system():
    """æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ"""
    print("ğŸ” ç³»ç»Ÿç¯å¢ƒæ£€æµ‹")
    print("=" * 50)
    
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"æ¶æ„: {platform.machine()}")
    
    # æ£€æŸ¥NVIDIAé©±åŠ¨
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIAé©±åŠ¨å·²å®‰è£…")
            print("GPUä¿¡æ¯:")
            lines = result.stdout.split('\n')
            for line in lines[:10]:  # æ˜¾ç¤ºå‰10è¡Œ
                if line.strip():
                    print(f"  {line}")
        else:
            print("âŒ NVIDIAé©±åŠ¨æœªå®‰è£…æˆ–ä¸å¯ç”¨")
            return False
    except FileNotFoundError:
        print("âŒ nvidia-smiå‘½ä»¤ä¸å¯ç”¨ï¼Œè¯·å®‰è£…NVIDIAé©±åŠ¨")
        return False
    
    return True

def install_pytorch_gpu():
    """å®‰è£…GPUç‰ˆæœ¬çš„PyTorch"""
    print("\nğŸš€ å®‰è£…GPUç‰ˆæœ¬PyTorch")
    print("=" * 50)
    
    # æ£€æµ‹CUDAç‰ˆæœ¬
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.split('\n')
            for line in lines:
                if 'release' in line.lower():
                    print(f"æ£€æµ‹åˆ°CUDA: {line.strip()}")
                    break
        else:
            print("âŒ CUDAæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…CUDA Toolkit")
            return False
    except FileNotFoundError:
        print("âŒ nvccå‘½ä»¤ä¸å¯ç”¨ï¼Œè¯·å®‰è£…CUDA Toolkit")
        return False
    
    # å®‰è£…PyTorch GPUç‰ˆæœ¬
    print("\nğŸ“¦ å®‰è£…PyTorch GPUç‰ˆæœ¬...")
    
    # æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©åˆé€‚çš„å®‰è£…å‘½ä»¤
    pytorch_commands = [
        # CUDA 12.1 (æ¨è)
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121",
        # CUDA 11.8 (å¤‡é€‰)
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
        # CUDA 12.4 (æœ€æ–°)
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124",
    ]
    
    for i, command in enumerate(pytorch_commands, 1):
        print(f"\nå°è¯•å®‰è£…å‘½ä»¤ {i}: {command}")
        try:
            result = subprocess.run(command.split(), check=True, capture_output=True, text=True)
            print("âœ… PyTorch GPUç‰ˆæœ¬å®‰è£…æˆåŠŸ!")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âŒ å®‰è£…å¤±è´¥: {e}")
            if i < len(pytorch_commands):
                print("å°è¯•ä¸‹ä¸€ä¸ªå®‰è£…å‘½ä»¤...")
            else:
                print("æ‰€æœ‰å®‰è£…å‘½ä»¤éƒ½å¤±è´¥äº†")
                return False
    
    return False

def install_ckip_transformers():
    """å®‰è£…CKIP Transformers"""
    print("\nğŸ“¦ å®‰è£…CKIP Transformers")
    print("=" * 50)
    
    try:
        # å®‰è£…CKIP Transformers
        result = subprocess.run([
            "pip", "install", "ckip-transformers"
        ], check=True, capture_output=True, text=True)
        print("âœ… CKIP Transformerså®‰è£…æˆåŠŸ!")
        
        # å®‰è£…å…¶ä»–ä¾èµ–
        dependencies = [
            "transformers>=4.20.0",
            "torch>=1.12.0",
            "numpy>=1.21.0",
            "loguru>=0.6.0",
            "click>=8.0.0",
            "pyyaml>=6.0",
        ]
        
        for dep in dependencies:
            print(f"å®‰è£…ä¾èµ–: {dep}")
            subprocess.run(["pip", "install", dep], check=True)
        
        print("âœ… æ‰€æœ‰ä¾èµ–å®‰è£…å®Œæˆ!")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ å®‰è£…å¤±è´¥: {e}")
        return False

def verify_installation():
    """éªŒè¯å®‰è£…"""
    print("\nâœ… éªŒè¯å®‰è£…")
    print("=" * 50)
    
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                print(f"GPU {i}: {gpu_name}, æ˜¾å­˜: {gpu_memory:.1f}GB")
        
        # æµ‹è¯•CKIP
        try:
            from ckip_transformers.nlp import CkipWordSegmenter
            print("âœ… CKIP Transformerså¯¼å…¥æˆåŠŸ!")
        except ImportError:
            print("âŒ CKIP Transformerså¯¼å…¥å¤±è´¥")
            return False
        
        print("âœ… æ‰€æœ‰ç»„ä»¶å®‰è£…éªŒè¯æˆåŠŸ!")
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æ™ºèƒ½æ’ç‰ˆç³»ç»Ÿ - GPUç‰ˆæœ¬å®‰è£…")
    print("=" * 60)
    print("æœ¬è„šæœ¬å°†ä¸ºæ‚¨å®‰è£…GPUç‰ˆæœ¬çš„PyTorchå’ŒCKIP Transformers")
    print("ç‰¹åˆ«é’ˆå¯¹4090Dæ˜¾å¡è¿›è¡Œä¼˜åŒ–")
    print("=" * 60)
    
    # æ£€æŸ¥ç³»ç»Ÿ
    if not check_system():
        print("\nâŒ ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆå®‰è£…NVIDIAé©±åŠ¨å’ŒCUDA Toolkit")
        return
    
    # å®‰è£…PyTorch GPUç‰ˆæœ¬
    if not install_pytorch_gpu():
        print("\nâŒ PyTorch GPUç‰ˆæœ¬å®‰è£…å¤±è´¥")
        return
    
    # å®‰è£…CKIP Transformers
    if not install_ckip_transformers():
        print("\nâŒ CKIP Transformerså®‰è£…å¤±è´¥")
        return
    
    # éªŒè¯å®‰è£…
    if not verify_installation():
        print("\nâŒ å®‰è£…éªŒè¯å¤±è´¥")
        return
    
    print("\nğŸ‰ GPUç‰ˆæœ¬å®‰è£…å®Œæˆ!")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. è¿è¡Œ 'python test_gpu.py' æ£€æµ‹GPUçŠ¶æ€")
    print("2. ä½¿ç”¨ '--device cuda:0' å‚æ•°å¯ç”¨GPUåŠ é€Ÿ")
    print("3. ç›‘æ§æ˜¾å­˜ä½¿ç”¨æƒ…å†µ: nvidia-smi")
    print("4. å¯¹äº4090Dï¼Œå»ºè®®ä½¿ç”¨è¾ƒå¤§çš„batch_size")
    
    print("\nğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨GPUåŠ é€Ÿçš„æ™ºèƒ½æ’ç‰ˆäº†!")

if __name__ == "__main__":
    main() 